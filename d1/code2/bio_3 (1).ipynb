{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLCNN3ZSKlgN",
        "outputId": "9ce03b39-2d93-4afe-e656-35bc7036ca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.1269 - loss: 3.1852 - val_accuracy: 0.2627 - val_loss: 2.6081\n",
            "Epoch 2/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.3300 - loss: 2.3076 - val_accuracy: 0.2877 - val_loss: 2.3395\n",
            "Epoch 3/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5059 - loss: 1.5872 - val_accuracy: 0.3022 - val_loss: 2.2999\n",
            "Epoch 4/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6572 - loss: 1.0505 - val_accuracy: 0.3038 - val_loss: 2.4230\n",
            "Epoch 5/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7403 - loss: 0.7671 - val_accuracy: 0.3046 - val_loss: 2.6603\n",
            "Epoch 6/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8010 - loss: 0.5951 - val_accuracy: 0.2933 - val_loss: 2.8113\n",
            "Epoch 7/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.8323 - loss: 0.5183 - val_accuracy: 0.2965 - val_loss: 2.9689\n",
            "Epoch 8/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8594 - loss: 0.4128 - val_accuracy: 0.3030 - val_loss: 3.1737\n",
            "Epoch 9/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8623 - loss: 0.3921 - val_accuracy: 0.2893 - val_loss: 3.2629\n",
            "Epoch 10/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8658 - loss: 0.4071 - val_accuracy: 0.2828 - val_loss: 3.6068\n",
            "Epoch 11/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8832 - loss: 0.3239 - val_accuracy: 0.2990 - val_loss: 3.2315\n",
            "Epoch 12/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8849 - loss: 0.2903 - val_accuracy: 0.2973 - val_loss: 3.4595\n",
            "Epoch 13/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8842 - loss: 0.3463 - val_accuracy: 0.2998 - val_loss: 3.7878\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3141 - loss: 2.2107\n",
            "Validation Loss: 2.299884080886841, Validation Accuracy: 0.3021756708621979\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "Predictions saved to 'predictions_combined_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 읽기\n",
        "train_file_path = '/content/train.csv'  # 학습 데이터 파일 경로\n",
        "test_file_path = '/content/test.csv'      # 테스트 데이터 파일 경로\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "train_data.fillna('WT', inplace=True)\n",
        "test_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "X_train = train_data.drop(columns=['ID', 'SUBCLASS'])  # ID와 SUBCLASS 열 제거\n",
        "y_train = train_data['SUBCLASS']\n",
        "\n",
        "# 특징 인코딩: 'WT'는 0, 그 외는 첫 글자 + 컬럼명 조합으로 변환\n",
        "def encode_feature(col):\n",
        "    return col.apply(lambda x: '' if x == 'WT' else f\"{x[0]}_{col.name}\")\n",
        "\n",
        "# 모든 특성에 대해 인코딩 적용\n",
        "X_train_encoded = X_train.apply(encode_feature)\n",
        "X_test_encoded = test_data.drop(columns=['ID']).apply(encode_feature)  # 테스트 데이터 인코딩\n",
        "\n",
        "# 레이블 인코딩\n",
        "le = LabelEncoder()\n",
        "for c in X_train_encoded.columns:\n",
        "    X_train_encoded[c] = le.fit_transform(X_train_encoded[c])\n",
        "\n",
        "# 테스트 데이터에도 동일한 인코딩 적용\n",
        "for c in X_test_encoded.columns:\n",
        "    if c in le.classes_:\n",
        "        X_test_encoded[c] = le.transform(X_test_encoded[c])\n",
        "    else:\n",
        "        X_test_encoded[c] = le.fit_transform(X_test_encoded[c])\n",
        "\n",
        "# 레이블 인코딩\n",
        "le_y = LabelEncoder()\n",
        "y_encoded = le_y.fit_transform(y_train)\n",
        "\n",
        "# 훈련 데이터와 검증 데이터 분리\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X_train_final = X_train_final.values\n",
        "X_val = X_val.values\n",
        "X_test_encoded = X_test_encoded.values\n",
        "\n",
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train_final.shape[1],)),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(le_y.classes_), activation='softmax')  # 클래스 수에 맞추어 출력 노드 수 설정\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train_final, y_train_final, validation_data=(X_val, y_val),\n",
        "          epochs=200, batch_size=32,\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "# 검증 데이터 평가\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "test_predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# 예측 결과 변환\n",
        "predicted_labels = le_y.inverse_transform(test_predictions.argmax(axis=1))\n",
        "\n",
        "# 결과를 DataFrame으로 저장\n",
        "results = pd.DataFrame({\n",
        "    'ID': test_data['ID'],\n",
        "    'SUBCLASS': predicted_labels\n",
        "})\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "results.to_csv('predictions_combined_data.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions_combined_data.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.SUBCLASS.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "Urf4k7J0NIK9",
        "outputId": "670028e8-5fbe-4a20-cdac-eb76f0317221"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBCLASS\n",
              "STES      745\n",
              "BRCA      503\n",
              "KIPAN     204\n",
              "COAD      153\n",
              "THCA      123\n",
              "GBMLGG    104\n",
              "SKCM       93\n",
              "PRAD       93\n",
              "LGG        90\n",
              "KIRC       76\n",
              "CESC       53\n",
              "OV         48\n",
              "UCEC       40\n",
              "LUAD       40\n",
              "HNSC       33\n",
              "TGCT       26\n",
              "LAML       26\n",
              "LUSC       23\n",
              "PAAD       15\n",
              "PCPG       15\n",
              "SARC       14\n",
              "BLCA       12\n",
              "ACC        10\n",
              "LIHC        4\n",
              "DLBC        3\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUBCLASS</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>STES</th>\n",
              "      <td>745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BRCA</th>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIPAN</th>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COAD</th>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THCA</th>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GBMLGG</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SKCM</th>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRAD</th>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGG</th>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIRC</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CESC</th>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OV</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UCEC</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUAD</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HNSC</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGCT</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAML</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUSC</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAAD</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCPG</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SARC</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BLCA</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACC</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LIHC</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DLBC</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 읽기\n",
        "train_file_path = '/content/train.csv'  # 학습 데이터 파일 경로\n",
        "test_file_path = '/content/test.csv'      # 테스트 데이터 파일 경로\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "train_data.fillna('WT', inplace=True)\n",
        "test_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "X_train = train_data.drop(columns=['ID', 'SUBCLASS'])  # ID와 SUBCLASS 열 제거\n",
        "y_train = train_data['SUBCLASS']\n",
        "\n",
        "# 특징 인코딩: 'WT'는 0, 그 외는 첫 글자 + 컬럼명 조합으로 변환\n",
        "def encode_feature(col):\n",
        "    return col.apply(lambda x: '' if x == 'WT' else f\"{x[0]}_{col.name}\")\n",
        "\n",
        "# 모든 특성에 대해 인코딩 적용\n",
        "X_train_encoded = X_train.apply(encode_feature)\n",
        "X_test_encoded = test_data.drop(columns=['ID']).apply(encode_feature)  # 테스트 데이터 인코딩\n",
        "\n",
        "# 레이블 인코딩\n",
        "le = LabelEncoder()\n",
        "for c in X_train_encoded.columns:\n",
        "    X_train_encoded[c] = le.fit_transform(X_train_encoded[c])\n",
        "\n",
        "# 테스트 데이터에도 동일한 인코딩 적용\n",
        "for c in X_test_encoded.columns:\n",
        "    if c in le.classes_:\n",
        "        X_test_encoded[c] = le.transform(X_test_encoded[c])\n",
        "    else:\n",
        "        X_test_encoded[c] = le.fit_transform(X_test_encoded[c])\n",
        "\n",
        "# 레이블 인코딩\n",
        "le_y = LabelEncoder()\n",
        "y_encoded = le_y.fit_transform(y_train)\n",
        "\n",
        "# 훈련 데이터와 검증 데이터 분리\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X_train_final = X_train_final.values\n",
        "X_val = X_val.values\n",
        "X_test_encoded = X_test_encoded.values\n",
        "\n",
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train_final.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(le_y.classes_), activation='softmax')  # 클래스 수에 맞추어 출력 노드 수 설정\n",
        "\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train_final, y_train_final, validation_data=(X_val, y_val),\n",
        "          epochs=200, batch_size=32,\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "# 검증 데이터 평가\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "test_predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# 예측 결과 변환\n",
        "predicted_labels = le_y.inverse_transform(test_predictions.argmax(axis=1))\n",
        "\n",
        "# 결과를 DataFrame으로 저장\n",
        "results = pd.DataFrame({\n",
        "    'ID': test_data['ID'],\n",
        "    'SUBCLASS': predicted_labels\n",
        "})\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "results.to_csv('p00001redictions_combined_data.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions_combined_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfKLIARPPAgp",
        "outputId": "d47e664f-89d2-406d-a943-ed8abe875ea5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.0462 - loss: 3.6910 - val_accuracy: 0.0967 - val_loss: 3.1521\n",
            "Epoch 2/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.0941 - loss: 3.2340 - val_accuracy: 0.1378 - val_loss: 3.0817\n",
            "Epoch 3/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.1266 - loss: 3.0573 - val_accuracy: 0.1821 - val_loss: 3.0262\n",
            "Epoch 4/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.1700 - loss: 2.9229 - val_accuracy: 0.2095 - val_loss: 2.9457\n",
            "Epoch 5/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.2223 - loss: 2.8218 - val_accuracy: 0.2385 - val_loss: 2.8510\n",
            "Epoch 6/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2482 - loss: 2.6875 - val_accuracy: 0.2425 - val_loss: 2.7435\n",
            "Epoch 7/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.2966 - loss: 2.5203 - val_accuracy: 0.2434 - val_loss: 2.6473\n",
            "Epoch 8/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.3156 - loss: 2.3662 - val_accuracy: 0.2458 - val_loss: 2.5650\n",
            "Epoch 9/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.3678 - loss: 2.1956 - val_accuracy: 0.2425 - val_loss: 2.5136\n",
            "Epoch 10/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.3910 - loss: 2.0410 - val_accuracy: 0.2522 - val_loss: 2.4586\n",
            "Epoch 11/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.4260 - loss: 1.9121 - val_accuracy: 0.2595 - val_loss: 2.4232\n",
            "Epoch 12/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4445 - loss: 1.8219 - val_accuracy: 0.2716 - val_loss: 2.3958\n",
            "Epoch 13/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4758 - loss: 1.7038 - val_accuracy: 0.2772 - val_loss: 2.3753\n",
            "Epoch 14/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5208 - loss: 1.5628 - val_accuracy: 0.2917 - val_loss: 2.3597\n",
            "Epoch 15/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.5563 - loss: 1.4347 - val_accuracy: 0.2925 - val_loss: 2.3757\n",
            "Epoch 16/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.5775 - loss: 1.3378 - val_accuracy: 0.2869 - val_loss: 2.3814\n",
            "Epoch 17/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.6133 - loss: 1.2341 - val_accuracy: 0.2949 - val_loss: 2.4056\n",
            "Epoch 18/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6385 - loss: 1.1344 - val_accuracy: 0.3014 - val_loss: 2.4093\n",
            "Epoch 19/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.6715 - loss: 1.0589 - val_accuracy: 0.2973 - val_loss: 2.4577\n",
            "Epoch 20/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.6873 - loss: 0.9734 - val_accuracy: 0.2957 - val_loss: 2.4974\n",
            "Epoch 21/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.7140 - loss: 0.8719 - val_accuracy: 0.2957 - val_loss: 2.5191\n",
            "Epoch 22/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7237 - loss: 0.8509 - val_accuracy: 0.2998 - val_loss: 2.6047\n",
            "Epoch 23/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7747 - loss: 0.7466 - val_accuracy: 0.3070 - val_loss: 2.5925\n",
            "Epoch 24/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7670 - loss: 0.7322 - val_accuracy: 0.2981 - val_loss: 2.6576\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3030 - loss: 2.2754\n",
            "Validation Loss: 2.359675884246826, Validation Accuracy: 0.29170024394989014\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Predictions saved to 'predictions_combined_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.SUBCLASS.value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "BSKqKt57PS1A",
        "outputId": "e93b4ab3-9faa-424b-c050-7f6bda55a8b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBCLASS\n",
              "BRCA      641\n",
              "COAD      392\n",
              "STES      350\n",
              "KIPAN     249\n",
              "GBMLGG    128\n",
              "KIRC      113\n",
              "SKCM      107\n",
              "THCA       81\n",
              "LGG        62\n",
              "UCEC       61\n",
              "OV         59\n",
              "HNSC       56\n",
              "LUSC       55\n",
              "LUAD       53\n",
              "CESC       41\n",
              "PRAD       29\n",
              "SARC       20\n",
              "LIHC       19\n",
              "BLCA       11\n",
              "PAAD        6\n",
              "ACC         4\n",
              "LAML        4\n",
              "PCPG        3\n",
              "TGCT        2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUBCLASS</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BRCA</th>\n",
              "      <td>641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COAD</th>\n",
              "      <td>392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STES</th>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIPAN</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GBMLGG</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIRC</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SKCM</th>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THCA</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGG</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UCEC</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OV</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HNSC</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUSC</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUAD</th>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CESC</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRAD</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SARC</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LIHC</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BLCA</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAAD</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACC</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAML</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCPG</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGCT</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK2x8CSHQLvz",
        "outputId": "d8db5d1a-283b-48e2-89b9-75a495b43256"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.0570 - loss: 3.6941 - val_accuracy: 0.1297 - val_loss: 3.1535 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.1060 - loss: 3.2143 - val_accuracy: 0.1636 - val_loss: 3.0857 - learning_rate: 1.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.1396 - loss: 3.0595 - val_accuracy: 0.1821 - val_loss: 3.0273 - learning_rate: 1.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.1693 - loss: 2.9207 - val_accuracy: 0.2168 - val_loss: 2.9476 - learning_rate: 1.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.2216 - loss: 2.8005 - val_accuracy: 0.2248 - val_loss: 2.8488 - learning_rate: 1.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.2646 - loss: 2.6403 - val_accuracy: 0.2409 - val_loss: 2.7296 - learning_rate: 1.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.3037 - loss: 2.4778 - val_accuracy: 0.2450 - val_loss: 2.6232 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.3265 - loss: 2.3302 - val_accuracy: 0.2530 - val_loss: 2.5494 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.3529 - loss: 2.1827 - val_accuracy: 0.2627 - val_loss: 2.4896 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.4002 - loss: 2.0326 - val_accuracy: 0.2732 - val_loss: 2.4432 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4252 - loss: 1.9103 - val_accuracy: 0.2756 - val_loss: 2.4140 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4659 - loss: 1.7607 - val_accuracy: 0.2853 - val_loss: 2.3899 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5068 - loss: 1.6315 - val_accuracy: 0.2957 - val_loss: 2.3594 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5469 - loss: 1.4978 - val_accuracy: 0.3022 - val_loss: 2.3510 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.5643 - loss: 1.3985 - val_accuracy: 0.2998 - val_loss: 2.3724 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.5895 - loss: 1.2868 - val_accuracy: 0.3086 - val_loss: 2.3772 - learning_rate: 1.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6346 - loss: 1.1905 - val_accuracy: 0.3038 - val_loss: 2.3807 - learning_rate: 1.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.6500 - loss: 1.1165 - val_accuracy: 0.3070 - val_loss: 2.3847 - learning_rate: 1.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6553 - loss: 1.0790 - val_accuracy: 0.3078 - val_loss: 2.3866 - learning_rate: 1.0000e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6485 - loss: 1.0926 - val_accuracy: 0.3110 - val_loss: 2.3927 - learning_rate: 1.0000e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6675 - loss: 1.0576 - val_accuracy: 0.3110 - val_loss: 2.3925 - learning_rate: 1.0000e-06\n",
            "Epoch 22/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6637 - loss: 1.0463 - val_accuracy: 0.3102 - val_loss: 2.3927 - learning_rate: 1.0000e-06\n",
            "Epoch 23/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.6604 - loss: 1.0633 - val_accuracy: 0.3110 - val_loss: 2.3926 - learning_rate: 1.0000e-06\n",
            "Epoch 24/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6615 - loss: 1.0766 - val_accuracy: 0.3110 - val_loss: 2.3926 - learning_rate: 1.0000e-07\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3213 - loss: 2.2738\n",
            "Validation Loss: 2.351006269454956, Validation Accuracy: 0.3021756708621979\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Predictions saved to 'predictions_combined_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.SUBCLASS.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "LBwu5e1QRdr7",
        "outputId": "cca14ef7-1e3f-4314-d2f0-b5222dbf9c6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBCLASS\n",
              "BRCA      609\n",
              "COAD      412\n",
              "KIPAN     306\n",
              "STES      251\n",
              "GBMLGG    143\n",
              "OV        118\n",
              "UCEC      114\n",
              "SKCM      101\n",
              "THCA       90\n",
              "PRAD       81\n",
              "HNSC       59\n",
              "KIRC       57\n",
              "LGG        36\n",
              "LUSC       29\n",
              "SARC       27\n",
              "LIHC       24\n",
              "LUAD       23\n",
              "CESC       22\n",
              "BLCA       12\n",
              "TGCT       10\n",
              "PAAD        9\n",
              "LAML        7\n",
              "ACC         6\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUBCLASS</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BRCA</th>\n",
              "      <td>609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COAD</th>\n",
              "      <td>412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIPAN</th>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STES</th>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GBMLGG</th>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OV</th>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UCEC</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SKCM</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THCA</th>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRAD</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HNSC</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KIRC</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGG</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUSC</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SARC</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LIHC</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUAD</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CESC</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BLCA</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGCT</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAAD</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAML</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACC</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "train_file_path = '/content/train.csv'\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "train_data.fillna('WT', inplace=True)\n",
        "\n",
        "X = train_data.drop(columns=['ID', 'SUBCLASS'])\n",
        "y = train_data['SUBCLASS']\n",
        "\n",
        "# 인코딩\n",
        "def encode_feature(col):\n",
        "    return col.apply(lambda x: '' if x == 'WT' else f\"{x[0]}_{col.name}\")\n",
        "\n",
        "X_encoded = X.apply(encode_feature)\n",
        "le = LabelEncoder()\n",
        "for c in X_encoded.columns:\n",
        "    X_encoded[c] = le.fit_transform(X_encoded[c])\n",
        "\n",
        "le_y = LabelEncoder()\n",
        "y_encoded = le_y.fit_transform(y)\n",
        "\n",
        "# 학습 및 검증 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 구성 (더 복잡한 구조)\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='leaky_relu', input_shape=(X_train.shape[1],)),  # Leaky ReLU 사용\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='leaky_relu'),  # Leaky ReLU 사용\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='leaky_relu'),  # Leaky ReLU 사용\n",
        "    layers.Dense(len(le_y.classes_), activation='softmax')  # 소프트맥스 활성화\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "          epochs=200, batch_size=32,\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "# 검증 데이터 평가\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5mdUF8jSGaB",
        "outputId": "23a7a95b-2431-4493-fa4f-34e3636877b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.1350 - loss: 3.4621 - val_accuracy: 0.2804 - val_loss: 2.4879\n",
            "Epoch 2/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3871 - loss: 2.0746 - val_accuracy: 0.3006 - val_loss: 2.4108\n",
            "Epoch 3/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.5169 - loss: 1.5775 - val_accuracy: 0.3038 - val_loss: 2.3729\n",
            "Epoch 4/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6438 - loss: 1.1354 - val_accuracy: 0.3086 - val_loss: 2.6019\n",
            "Epoch 5/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.7133 - loss: 0.9385 - val_accuracy: 0.3086 - val_loss: 3.0874\n",
            "Epoch 6/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.7679 - loss: 0.7019 - val_accuracy: 0.2990 - val_loss: 3.1983\n",
            "Epoch 7/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8208 - loss: 0.5362 - val_accuracy: 0.3006 - val_loss: 3.6485\n",
            "Epoch 8/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.8146 - loss: 0.5323 - val_accuracy: 0.2998 - val_loss: 3.8072\n",
            "Epoch 9/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8213 - loss: 0.4937 - val_accuracy: 0.2877 - val_loss: 3.9944\n",
            "Epoch 10/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8351 - loss: 0.4886 - val_accuracy: 0.2909 - val_loss: 3.9919\n",
            "Epoch 11/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8579 - loss: 0.3741 - val_accuracy: 0.2981 - val_loss: 4.3611\n",
            "Epoch 12/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8683 - loss: 0.3728 - val_accuracy: 0.2957 - val_loss: 4.5724\n",
            "Epoch 13/200\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8693 - loss: 0.3544 - val_accuracy: 0.2756 - val_loss: 5.2141\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3258 - loss: 2.2113\n",
            "Validation Loss: 2.372868537902832, Validation Accuracy: 0.3037872612476349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 읽기\n",
        "train_file_path = '/content/train.csv'  # 학습 데이터 파일 경로\n",
        "test_file_path = '/content/test.csv'      # 테스트 데이터 파일 경로\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "train_data.fillna('WT', inplace=True)\n",
        "test_data.fillna('WT', inplace=True)\n",
        "\n",
        "test_data['SUBCLASS'] = None\n",
        "# 학습 데이터와 테스트 데이터 결합\n",
        "combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "#X_train = train_data.drop(columns=['ID', 'SUBCLASS'])  # ID와 SUBCLASS 열 제거\n",
        "#y_train = train_data['SUBCLASS']\n",
        "# 특징과 타겟 분리\n",
        "X = combined_data.drop(columns=['ID', 'SUBCLASS'])\n",
        "y = combined_data['SUBCLASS']\n",
        "\n",
        "# 특징 인코딩: 'WT'는 0, 그 외는 첫 글자 + 컬럼명 조합으로 변환\n",
        "def encode_feature(col):\n",
        "    return col.apply(lambda x: '' if x == 'WT' else f\"{str(x)[0]}_{col.name}\")\n",
        "\n",
        "# 모든 특성에 대해 인코딩 적용\n",
        "X_encoded = X_encoded.apply(encode_feature)\n",
        "\n",
        "# 레이블 인코딩\n",
        "le = LabelEncoder()\n",
        "for c in X_encoded.columns:\n",
        "    X_encoded[c] = le.fit_transform(X_encoded[c])\n",
        "\n",
        "\n",
        "# 레이블 인코딩\n",
        "le_y = LabelEncoder()\n",
        "y_encoded = le_y.fit_transform(y_train)\n",
        "\n",
        "\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "y_encoded_full = pd.Series([None] * len(combined_data), index=combined_data.index)\n",
        "y_encoded_full.iloc[:len(y_encoded)] = y_encoded\n",
        "\n",
        "# 학습/검증 데이터 분리\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_encoded[:len(y_encoded)], y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# 훈련 데이터와 검증 데이터 분리\n",
        "#X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X_train_final = X_train_final.values\n",
        "X_val = X_val.values\n",
        "\n",
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train_final.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(le_y.classes_), activation='softmax')  # 클래스 수에 맞추어 출력 노드 수 설정\n",
        "\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train_final, y_train_final, validation_data=(X_val, y_val),\n",
        "          epochs=200, batch_size=32,\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "# 검증 데이터 평가\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "X_test_encoded = X_encoded[len(y_encoded):]\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "#test_predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# 예측 결과 변환\n",
        "predicted_classes = predictions.argmax(axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "B0-tQZ8FSfSk",
        "outputId": "d8299df8-659d-483b-fdb8-46a98eac5e98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.0773 - loss: 3.2765 - val_accuracy: 0.1351 - val_loss: 3.1553\n",
            "Epoch 2/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.1372 - loss: 3.0655 - val_accuracy: 0.1280 - val_loss: 3.1252\n",
            "Epoch 3/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.1868 - loss: 2.9129 - val_accuracy: 0.1139 - val_loss: 3.1216\n",
            "Epoch 4/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2332 - loss: 2.6815 - val_accuracy: 0.1139 - val_loss: 3.1747\n",
            "Epoch 5/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3536 - loss: 2.3018 - val_accuracy: 0.1018 - val_loss: 3.3453\n",
            "Epoch 6/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4680 - loss: 1.9248 - val_accuracy: 0.0847 - val_loss: 3.6185\n",
            "Epoch 7/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.5686 - loss: 1.6077 - val_accuracy: 0.0786 - val_loss: 3.9390\n",
            "Epoch 8/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6607 - loss: 1.2901 - val_accuracy: 0.0877 - val_loss: 4.3808\n",
            "Epoch 9/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7228 - loss: 1.0454 - val_accuracy: 0.0706 - val_loss: 4.5987\n",
            "Epoch 10/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7715 - loss: 0.8813 - val_accuracy: 0.0746 - val_loss: 4.9574\n",
            "Epoch 11/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8217 - loss: 0.7643 - val_accuracy: 0.0776 - val_loss: 5.2372\n",
            "Epoch 12/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8226 - loss: 0.7002 - val_accuracy: 0.0756 - val_loss: 5.4161\n",
            "Epoch 13/200\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8315 - loss: 0.6400 - val_accuracy: 0.0806 - val_loss: 5.6950\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1151 - loss: 3.0984\n",
            "Validation Loss: 3.121645212173462, Validation Accuracy: 0.11391129344701767\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: [10 11 15 19 20 21 23 25]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1f3e3e836070>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# 레이블 인코딩된 클래스를 원래 클래스 이름으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains previously unseen labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [10 11 15 19 20 21 23 25]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 레이블 인코딩된 클래스를 원래 클래스 이름으로 변환\n",
        "predicted_labels = le_y.inverse_transform(predicted_classes)\n",
        "\n",
        "\n",
        "# 예측 결과 변환\n",
        "#predicted_labels = le_y.inverse_transform(test_predictions.argmax(axis=1))\n",
        "\n",
        "# 결과를 DataFrame으로 저장\n",
        "results = pd.DataFrame({\n",
        "    'ID': test_data['ID'],\n",
        "    'SUBCLASS': predicted_labels\n",
        "})\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "results.to_csv('combined_p00001redictions_combined_data.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions_combined_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "bdxMlA43Un5d",
        "outputId": "7f75ca4a-106a-4b22-a515-5608a868fd18"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "array length 1241 does not match index length 2546",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9568074c9632>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 결과를 DataFrame으로 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m results = pd.DataFrame({\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m'ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m'SUBCLASS'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    688\u001b[0m                     \u001b[0;34mf\"length {len(index)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 )\n\u001b[0;32m--> 690\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: array length 1241 does not match index length 2546"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from imblearn.over_sampling import SMOTE  # SMOTE 사용을 위한 라이브러리 추가\n",
        "\n",
        "# 학습 데이터 읽기\n",
        "train_file_path = '/content/train.csv'  # 학습 데이터 파일 경로\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "train_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 테스트 데이터 읽기\n",
        "test_file_path = '/content/test.csv'  # 테스트 데이터 파일 경로\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "test_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 테스트 데이터에 SUBCLASS 열 추가 (NaN으로 설정)\n",
        "test_data['SUBCLASS'] = None\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 결합\n",
        "combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "X = combined_data.drop(columns=['ID', 'SUBCLASS'])  # ID와 SUBCLASS 열 제거\n",
        "y = combined_data['SUBCLASS']\n",
        "\n",
        "# 특징 인코딩: 'WT'는 0, 그 외는 1로 변환\n",
        "X_encoded = X.apply(lambda col: col.map(lambda x: 0 if x == 'WT' else 1))\n",
        "\n",
        "# 레이블 인코딩 (학습 데이터에만 적용)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y.dropna())  # NaN을 제외하고 인코딩\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "y_encoded_full = pd.Series([None] * len(combined_data), index=combined_data.index)  # 초기화\n",
        "y_encoded_full.iloc[:len(y_encoded)] = y_encoded  # 학습 데이터에 대해서만 값 설정\n",
        "\n",
        "# 학습/검증 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_encoded[:len(y_encoded)], y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dropout(0.3),  # 드롭아웃 비율 조정\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),  # 드롭아웃 비율 조정\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')  # 클래스 수에 맞추어 출력 노드 수 설정\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16, callbacks=[early_stopping])\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "X_test_encoded = X_encoded[len(y_encoded):]  # 테스트 데이터 부분\n",
        "\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# 예측 결과 변환\n",
        "predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "# 레이블 인코딩된 클래스를 원래 클래스 이름으로 변환\n",
        "predicted_labels = le.inverse_transform(predicted_classes)\n",
        "\n",
        "# 결과를 DataFrame으로 저장\n",
        "results = pd.DataFrame({\n",
        "    'ID': test_data['ID'],\n",
        "    'SUBCLASS': predicted_labels\n",
        "})\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "results.to_csv('maybe_predictions_no_scaler.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions_no_scaler.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ShQD4stWZaN",
        "outputId": "58ac2c81-d69b-47bc-d46c-6a612a81b21a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.1679 - loss: 2.9185 - val_accuracy: 0.2981 - val_loss: 2.3803\n",
            "Epoch 2/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.5024 - loss: 1.5784 - val_accuracy: 0.3521 - val_loss: 2.1146\n",
            "Epoch 3/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7476 - loss: 0.7406 - val_accuracy: 0.3288 - val_loss: 2.4988\n",
            "Epoch 4/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.8422 - loss: 0.4149 - val_accuracy: 0.3175 - val_loss: 2.8838\n",
            "Epoch 5/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8870 - loss: 0.3416 - val_accuracy: 0.3151 - val_loss: 2.9985\n",
            "Epoch 6/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8968 - loss: 0.2448 - val_accuracy: 0.3159 - val_loss: 3.3755\n",
            "Epoch 7/100\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9113 - loss: 0.2029 - val_accuracy: 0.2917 - val_loss: 3.5270\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Predictions saved to 'predictions_no_scaler.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from imblearn.over_sampling import SMOTE  # SMOTE 사용을 위한 라이브러리 추가\n",
        "\n",
        "# 학습 데이터 읽기\n",
        "train_file_path = '/content/train.csv'  # 학습 데이터 파일 경로\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "train_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 테스트 데이터 읽기\n",
        "test_file_path = '/content/test.csv'  # 테스트 데이터 파일 경로\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# 결측값 처리\n",
        "test_data.fillna('WT', inplace=True)\n",
        "\n",
        "# 테스트 데이터에 SUBCLASS 열 추가 (NaN으로 설정)\n",
        "test_data['SUBCLASS'] = None\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 결합\n",
        "combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "X = combined_data.drop(columns=['ID', 'SUBCLASS'])  # ID와 SUBCLASS 열 제거\n",
        "y = combined_data['SUBCLASS']\n",
        "\n",
        "# 특징 인코딩: 'WT'는 0, 그 외는 1로 변환\n",
        "X_encoded = X.apply(lambda col: col.map(lambda x: 0 if x == 'WT' else 1))\n",
        "\n",
        "# 레이블 인코딩 (학습 데이터에만 적용)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y.dropna())  # NaN을 제외하고 인코딩\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "y_encoded_full = pd.Series([None] * len(combined_data), index=combined_data.index)  # 초기화\n",
        "y_encoded_full.iloc[:len(y_encoded)] = y_encoded  # 학습 데이터에 대해서만 값 설정\n",
        "\n",
        "# 학습/검증 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_encoded[:len(y_encoded)], y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dropout(0.3),  # 드롭아웃 비율 조정\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),  # 드롭아웃 비율 조정\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')  # 클래스 수에 맞추어 출력 노드 수 설정\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16, callbacks=[early_stopping])\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "X_test_encoded = X_encoded[len(y_encoded):]  # 테스트 데이터 부분\n",
        "\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# 예측 결과 변환\n",
        "predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "# 레이블 인코딩된 클래스를 원래 클래스 이름으로 변환\n",
        "predicted_labels = le.inverse_transform(predicted_classes)\n",
        "\n",
        "# 결과를 DataFrame으로 저장\n",
        "results = pd.DataFrame({\n",
        "    'ID': test_data['ID'],\n",
        "    'SUBCLASS': predicted_labels\n",
        "})\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "results.to_csv('maybe_predictions_no_scaler.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions_no_scaler.csv'.\")\n"
      ],
      "metadata": {
        "id": "k-q-WnlXXBdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}