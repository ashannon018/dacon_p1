{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/x1jkjm3549s21y3h3k_k56q80000gn/T/ipykernel_54885/3631570316.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace('WT', 0, inplace=True)\n",
      "/Users/s/.pyenv/versions/3.10.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [   3   86  117  118  119  120  121  122  213  352  353  354  355  356\n",
      "  357  358  359  360  361  362  363  364  365  366  470  561  570  571\n",
      "  572  600  601  602  733  856  896  943  948 1007 1058 1099 1140 1167\n",
      " 1229 1233 1286 1291 1320 1337 1349 1427 1510 1521 1577 1639 1661 1664\n",
      " 1674 1679 1702 1703 1707 1716 1717 1718 1719 1720 1721 1722 1723 1724\n",
      " 1725 1726 1738 1873 1876 2012 2072 2077 2152 2153 2185 2214 2278 2304\n",
      " 2328 2329 2330 2331 2394 2395 2396 2400 2415 2445 2472 2478 2489 2525\n",
      " 2620 2621 2622 2623 2661 2662 2665 2691 2739 2764 2815 2829 2906 2952\n",
      " 3005 3011 3031 3032 3071 3138 3159 3179 3240 3257 3263 3294 3325 3343\n",
      " 3362 3391 3477 3526 3533 3534 3535 3538 3541 3542 3609 3687 3696 3697\n",
      " 3794 3810 3824 3865 3934 3936 3937 3964 3965 3966 4025 4097 4101 4292\n",
      " 4296 4332] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/s/.pyenv/versions/3.10.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (ANOVA): Index(['ABCC8', 'ALMS1', 'APC', 'ATRX', 'BRAF', 'BTG1', 'C8B', 'CDKN2A', 'CKB',\n",
      "       'COL11A1', 'CTNNB1', 'DCC', 'DPYD', 'FBXW7', 'IDH1', 'IDUA', 'KMT2D',\n",
      "       'LRIG1', 'MXRA5', 'MYH1', 'MYH2', 'MYH4', 'MYH8', 'NFKB2', 'NPM1',\n",
      "       'NUDT19', 'OSMR', 'PCLO', 'PEX6', 'PGLS', 'PIK3CA', 'PLCB4', 'PTEN',\n",
      "       'PTGIR', 'PTPRD', 'RELN', 'RYR1', 'RYR2', 'SAMD9', 'SCN10A', 'SCN9A',\n",
      "       'SOWAHC', 'SPTA1', 'SRD5A1', 'SYNE1', 'THEM4', 'TM7SF2', 'TP53', 'TP63',\n",
      "       'VHL'],\n",
      "      dtype='object')\n",
      "Accuracy with selected features: 0.273972602739726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s/.pyenv/versions/3.10.10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+03, tolerance: 2.737e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (Lasso): Index(['A2M', 'AAAS', 'ABAT', 'ABCA1', 'ABCA4', 'ABCA5', 'ABCA8', 'ABCA9',\n",
      "       'ABCB1', 'ABCB4',\n",
      "       ...\n",
      "       'ZNF185', 'ZNF277', 'ZNF365', 'ZNF639', 'ZNF707', 'ZNFX1', 'ZNRF4',\n",
      "       'ZPBP', 'ZW10', 'ZYX'],\n",
      "      dtype='object', length=2893)\n",
      "Accuracy with selected features: 0.273972602739726\n",
      "Selected features (Random Forest): Index(['FBN1', 'COL12A1', 'MTOR', 'AHNAK', 'PTPRD', 'RELN', 'COL6A3', 'SCN10A',\n",
      "       'FBN2', 'PEG3', 'DOCK2', 'COL11A1', 'TG', 'MYH2', 'PABPC1', 'LAMA1',\n",
      "       'PKHD1', 'MYH4', 'FBXW7', 'NOTCH1', 'PLEC', 'DMD', 'DST', 'HRAS', 'KIT',\n",
      "       'NF1', 'MXRA5', 'IDH2', 'RYR1', 'SPTA1', 'CDKN2A', 'KMT2D', 'MAP3K1',\n",
      "       'RYR2', 'SPOP', 'SYNE1', 'PCLO', 'EGFR', 'CTNNB1', 'GATA3', 'CDH1',\n",
      "       'NPM1', 'PTEN', 'ATRX', 'APC', 'PIK3CA', 'TP53', 'VHL', 'IDH1', 'BRAF'],\n",
      "      dtype='object')\n",
      "Accuracy with selected features: 0.27961321514907334\n",
      "Explained variance ratio (PCA): [0.05730761 0.01007562 0.00947473 0.00927449 0.00851876 0.00841707\n",
      " 0.00725334 0.00707946 0.00659723 0.00649655 0.00611382 0.00601989\n",
      " 0.00564921 0.00543974 0.00528457 0.00518975 0.00476704 0.0046835\n",
      " 0.00425771 0.00409095 0.00386153 0.00377435 0.00367654 0.00345899\n",
      " 0.00330113 0.00322153 0.00317888 0.00309457 0.00304837 0.00297996\n",
      " 0.00296441 0.00291981 0.00284387 0.00281683 0.00279536 0.00277263\n",
      " 0.0027216  0.00267933 0.00264622 0.0025803  0.00256189 0.00251916\n",
      " 0.00248645 0.00247028 0.00243932 0.00242428 0.00239501 0.00233714\n",
      " 0.00231968 0.00229458]\n",
      "Accuracy with PCA components: 0.18936341659951653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# 1. 파일 읽기 및 전처리\n",
    "csv_file_path = './input/train.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 'WT'를 0으로 변환\n",
    "df.replace('WT', 0, inplace=True)\n",
    "\n",
    "# ID 컬럼 제거\n",
    "X = df.drop(columns=['ID', 'SUBCLASS'])\n",
    "y = df['SUBCLASS']\n",
    "\n",
    "# 데이터 타입 확인 및 혼합된 열 처리\n",
    "def convert_mixed_columns_to_string(X):\n",
    "    \"\"\"숫자와 문자열이 혼합된 열을 모두 문자열로 변환\"\"\"\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':  # 문자열 타입 열\n",
    "            X[col] = X[col].astype(str)\n",
    "    return X\n",
    "\n",
    "X = convert_mixed_columns_to_string(X)\n",
    "\n",
    "# 나머지 문자열 데이터를 수치형으로 변환\n",
    "# 모든 문자열 컬럼을 LabelEncoder를 통해 변환 (범주형 데이터 인코딩)\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# SUBCLASS(target)도 LabelEncoder로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# 2. 학습/테스트 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. 특성 선택 방법 적용 및 성능 평가 함수\n",
    "def evaluate_features(X_train, X_test, y_train, y_test, selected_features):\n",
    "    \"\"\" 선택된 feature들로 학습 후 성능을 평가 \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train[selected_features], y_train)\n",
    "    y_pred = rf.predict(X_test[selected_features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with selected features: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "## 방법 1: 통계 기반 특성 선택 (ANOVA)\n",
    "def select_kbest_anova(X_train, X_test, y_train, y_test, k=50):\n",
    "    anova_selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_selected = anova_selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = anova_selector.transform(X_test)\n",
    "    selected_feature_indices = anova_selector.get_support(indices=True)\n",
    "    selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "    print(f\"Selected features (ANOVA): {selected_feature_names}\")\n",
    "    return selected_feature_names\n",
    "\n",
    "## 방법 2: Lasso (L1 Regularization)\n",
    "def select_lasso(X_train, X_test, y_train, y_test, alpha=0.01):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    selected_features = X_train.columns[(lasso.coef_ != 0)]\n",
    "    print(f\"Selected features (Lasso): {selected_features}\")\n",
    "    return selected_features\n",
    "\n",
    "## 방법 3: 랜덤 포레스트 기반 특성 중요도\n",
    "def select_random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[-50:]  # 상위 50개의 중요한 특성\n",
    "    selected_features = X_train.columns[indices]\n",
    "    print(f\"Selected features (Random Forest): {selected_features}\")\n",
    "    return selected_features\n",
    "\n",
    "## 방법 4: PCA (주성분 분석)\n",
    "def apply_pca(X_train, X_test, n_components=50):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    print(f\"Explained variance ratio (PCA): {pca.explained_variance_ratio_}\")\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "# 예시 실행 및 성능 평가\n",
    "\n",
    "# ANOVA 방식\n",
    "selected_features_anova = select_kbest_anova(X_train, X_test, y_train, y_test)\n",
    "evaluate_features(X_train, X_test, y_train, y_test, selected_features_anova)\n",
    "\n",
    "# Lasso 방식\n",
    "selected_features_lasso = select_lasso(X_train, X_test, y_train, y_test)\n",
    "evaluate_features(X_train, X_test, y_train, y_test, selected_features_lasso)\n",
    "\n",
    "# Random Forest 방식\n",
    "selected_features_rf = select_random_forest(X_train, X_test, y_train, y_test)\n",
    "evaluate_features(X_train, X_test, y_train, y_test, selected_features_rf)\n",
    "\n",
    "# PCA 방식은 차원을 줄이는 것이므로 RandomForest와 같이 특성 선택으로 바로 평가할 수 없습니다.\n",
    "X_train_pca, X_test_pca = apply_pca(X_train, X_test)\n",
    "rf_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = rf_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"Accuracy with PCA components: {accuracy_pca}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
